{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FptMQKUxMLzB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, MultiHeadAttention, Dense, Input, Dropout, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL7NwzG1MLzG",
        "outputId": "d32b39c1-0512-443a-8693-6a8ec768f7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa0549iWW7Wk",
        "outputId": "245a582f-0ade-4c33-a57f-af5b1bb92fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb  9 17:36:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    34W / 250W |    375MiB / 16280MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-2K1_vdXgL5",
        "outputId": "8cd5d2be-558a-4809-dd75-ca5f6c1dd707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1JPeppzYrwN",
        "outputId": "7d8f4532-e983-4660-e884-d17fd399e41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/text_summerization/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQNqCjOzK2Vf",
        "outputId": "0245040a-c4fd-4390-892a-95eda266e215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/text_summerization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zen3ERwIMLzI",
        "outputId": "8ceb25d9-59fd-42bc-e559-cb0d17ae8fb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7dbc539-b980-4434-82c8-6b2e436f07e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7dbc539-b980-4434-82c8-6b2e436f07e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7dbc539-b980-4434-82c8-6b2e436f07e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7dbc539-b980-4434-82c8-6b2e436f07e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 Summary                                               Text\n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
              "4            Great taffy  Great taffy at a great price.  There was a wid..."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "data = pd.read_csv('Reviews.csv')\n",
        "reviews = data[['Summary','Text']]\n",
        "reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxfoxh_IMLzJ",
        "outputId": "0d3a1b0c-e597-447a-add8-ca4dacb63976"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Summary    27\n",
              "Text        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "reviews.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHcOi_RGMLzK"
      },
      "outputs": [],
      "source": [
        "reviews = reviews.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HGDyARLOMLzK",
        "outputId": "c42b7a0b-a9f5-4651-f52b-5319ab1e9903"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-58d06cfd-6d68-4cf9-a3b6-631af6a76534\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tried a second time and it was great!</td>\n",
              "      <td>My husband bought me the Kuereg so I could mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great tasting tuna</td>\n",
              "      <td>This is very good quality tuna fillet and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Need to seal the tops better</td>\n",
              "      <td>Granted that I live nearly 2 miles above sea l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GREAT product</td>\n",
              "      <td>I have really bad arthritis and usually have t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great stuff</td>\n",
              "      <td>Having only eaten instant oatmeal, I was looki...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58d06cfd-6d68-4cf9-a3b6-631af6a76534')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58d06cfd-6d68-4cf9-a3b6-631af6a76534 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58d06cfd-6d68-4cf9-a3b6-631af6a76534');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 Summary                                               Text\n",
              "0  Tried a second time and it was great!  My husband bought me the Kuereg so I could mak...\n",
              "1                     Great tasting tuna  This is very good quality tuna fillet and is s...\n",
              "2           Need to seal the tops better  Granted that I live nearly 2 miles above sea l...\n",
              "3                          GREAT product  I have really bad arthritis and usually have t...\n",
              "4                            Great stuff  Having only eaten instant oatmeal, I was looki..."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "# shuffling the data \n",
        "reviews = shuffle(reviews)\n",
        "reviews = reviews.reset_index(drop=True)\n",
        "reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQSXEmOnMLzL"
      },
      "outputs": [],
      "source": [
        "summary, review_text = pd.DataFrame(), pd.DataFrame()\n",
        "summary['Summary'] = reviews['Summary']\n",
        "review_text['Text'] = reviews['Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew4jn0tsMLzL",
        "outputId": "f245157c-922f-454d-9e29-38402bb7b94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "short form: ain't ;  long form: is not\n"
          ]
        }
      ],
      "source": [
        "contraction_mapping = np.load('contraction_mapping.npy', allow_pickle=True).item()\n",
        "(short,long) = next(iter(contraction_mapping.items()))\n",
        "print('short form:', short, ';  long form:', long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws_ouno5MLzM"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imV95Kj5MLzN"
      },
      "outputs": [],
      "source": [
        "def clean_data(text, remove_stopwords=False):\n",
        "    \n",
        "    # Make all words lowercase\n",
        "    text = str(text).lower()\n",
        "    \n",
        "    # Format words and remove unwanted characters\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    \n",
        "    text = text.split()\n",
        "    \n",
        "    # Remove stopwords that are not important for the meaning of a sentence\n",
        "    if(remove_stopwords):\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in stop_words:\n",
        "                continue\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = new_text\n",
        "    \n",
        "    # Replace contractions with their longer forms \n",
        "    new_text = []\n",
        "    for word in text:\n",
        "        if word in contraction_mapping:\n",
        "            new_text.append(contraction_mapping[word])\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "    text = \" \".join(new_text)\n",
        "      \n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    \n",
        "    return text\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDD_uochMLzN"
      },
      "outputs": [],
      "source": [
        "summary['Summary'] = summary['Summary'].apply(lambda x: clean_data(x, remove_stopwords=True))\n",
        "review_text['Text'] = review_text['Text'].apply(lambda x: clean_data(x, remove_stopwords=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QqpAndNRMLzO",
        "outputId": "39a295db-c1c4-4018-ca06-8a58b3730db3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b32fcefc-abab-4576-b79a-9df0410f23c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tried second time great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>great tasting tuna</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>need seal tops better</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>great product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great stuff</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b32fcefc-abab-4576-b79a-9df0410f23c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b32fcefc-abab-4576-b79a-9df0410f23c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b32fcefc-abab-4576-b79a-9df0410f23c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                   Summary\n",
              "0  tried second time great\n",
              "1       great tasting tuna\n",
              "2    need seal tops better\n",
              "3            great product\n",
              "4              great stuff"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "summary.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9lPCjklnMLzO",
        "outputId": "5ee220d7-9047-4ca6-e5ab-adbd6d29598b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-788cbcf8-6fa8-425c-984d-3a987a3dbb7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>husband bought kuereg could make flavored coff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good quality tuna fillet superior national bra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>granted live nearly 2 miles sea level packagin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>really bad arthritis usually take aleve everyd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eaten instant oatmeal looking whole grain oatm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-788cbcf8-6fa8-425c-984d-3a987a3dbb7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-788cbcf8-6fa8-425c-984d-3a987a3dbb7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-788cbcf8-6fa8-425c-984d-3a987a3dbb7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                Text\n",
              "0  husband bought kuereg could make flavored coff...\n",
              "1  good quality tuna fillet superior national bra...\n",
              "2  granted live nearly 2 miles sea level packagin...\n",
              "3  really bad arthritis usually take aleve everyd...\n",
              "4  eaten instant oatmeal looking whole grain oatm..."
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "review_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3Cl4p4vQMLzP",
        "outputId": "2f4e2987-bbfd-4d6f-f035-2b9968af24ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b45a3322-d243-4b43-8941-7eb2a526d8d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tried a second time and it was great!</td>\n",
              "      <td>My husband bought me the Kuereg so I could mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great tasting tuna</td>\n",
              "      <td>This is very good quality tuna fillet and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Need to seal the tops better</td>\n",
              "      <td>Granted that I live nearly 2 miles above sea l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GREAT product</td>\n",
              "      <td>I have really bad arthritis and usually have t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great stuff</td>\n",
              "      <td>Having only eaten instant oatmeal, I was looki...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b45a3322-d243-4b43-8941-7eb2a526d8d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b45a3322-d243-4b43-8941-7eb2a526d8d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b45a3322-d243-4b43-8941-7eb2a526d8d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 Summary                                               Text\n",
              "0  Tried a second time and it was great!  My husband bought me the Kuereg so I could mak...\n",
              "1                     Great tasting tuna  This is very good quality tuna fillet and is s...\n",
              "2           Need to seal the tops better  Granted that I live nearly 2 miles above sea l...\n",
              "3                          GREAT product  I have really bad arthritis and usually have t...\n",
              "4                            Great stuff  Having only eaten instant oatmeal, I was looki..."
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlU7kPSiMLzP"
      },
      "outputs": [],
      "source": [
        "# Remove data which only consists of stopwords.\n",
        "ind = (summary['Summary']!='')&(review_text['Text']!='')\n",
        "summary = summary[ind]\n",
        "review_text = review_text[ind]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5tevc19MLzQ"
      },
      "outputs": [],
      "source": [
        "def count_length(data):\n",
        "    length = {}\n",
        "    for text in data:\n",
        "        l = len(text.split())\n",
        "        if(l not in length):\n",
        "            length[l] = 1\n",
        "        else:\n",
        "            length[l] += 1\n",
        "    \n",
        "    stats = np.zeros(max(length)+1)\n",
        "    \n",
        "    for i in length:\n",
        "        stats[i] = length[i]\n",
        "    total = np.sum(stats)\n",
        "    cdf = np.cumsum(stats) / total\n",
        "    \n",
        "    return stats, cdf\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5z-5QuhMLzQ"
      },
      "outputs": [],
      "source": [
        "text_length, text_length_cdf = count_length(review_text['Text'])\n",
        "summary_length, summary_length_cdf = count_length(summary['Summary'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "0JY66Gj5MLzR",
        "outputId": "b6ae0aa8-9967-4063-a251-90292a832f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For long review texts, 90% of the data has <= 85 words, 95% of the data has <= 117 words,  and 99% of the data has <= 211 words\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAe8UlEQVR4nO3dfbRVdb3v8fdHzHwWlB0hSBsN7aijMPf14fpwSU3RumFmJZXiwxEdyenBGoV1RnYtx6B7LNPy4iAl8RyDuBpJSRFpIo0bCiRXAfO6VZRNCAg+HTUL/N4/5m/JZLvX3ovNnmutvdbnNcYce87vfPrNxdz7y+83f+s3FRGYmZkVaZdaF8DMzBqfk42ZmRXOycbMzArnZGNmZoVzsjEzs8I52ZiZWeGcbKxfk7Ra0mm1LsfOkLRS0phal8OsSE42ZjUWEUdExP1FHV/ShZL+WG/HsubiZGO2kyTtWusymNU7JxtrGJLeKemHkv6aph9KemdaN0ZSh6SvSNogaZ2ki3L7HiDpV5JelrRE0nfL/Q9eUqukkHSJpGeB+1L8YkmPSXpB0nxJ70nxqZKu63SMuyVdmebfagqUtIukyZKelLRJ0mxJ+6d1MyR9Jc0PS2W4Ii0fImmzpF06neefgJuB4yX9p6QXc5/VdZKelbRe0s2S9kjr5kn6fu4YsyRN7+ZYZ0laJekVSWslfbVX/4DW0JxsrJF8EzgOGA18ADgG+Nfc+ncD+wHDgEuAmyQNSutuAl5N20xIU0/+G/BPwBmSxgHfAM4BWoBFwMy03Uzg05IEkM55OjCri2P+C3B2OvaBwAupbAALgTG5cz8FnJxbXhQRb+YPFhGPAZcDf4qIvSNiYFo1BTiU7LN6b/pMvpXWXQycL+kUSZ8l+xy/2M2xbgUui4h9gCNJyddsOxHhyVO/nYDVwGlp/kngrNy6M4DVaX4M8Dqwa279BrLkNAD4B3BYbt13gT+WOWcrEMDBudhvgEtyy7sArwHvAQQ8C5yc1l0K3FfmGh4DTs2tG5rKtitwCFny2YWshnEZ0JG2mwFcWaa8F+avJZXnVeCQXOx44Onc8ieANcDzwInljpViz6ay7Fvr+8FT/U6u2VgjORB4Jrf8TIqVbIqILbnl14C9yWoiu5L9cS3Jz5eT3+Y9wA2SXkzNS5vJ/qgPi4ggq8WMT9t+BrijzDHfA8zJHecxYCswJCKeJEsSo4GTgF8Df5V0GFnNZmEFZYbsevcEluXO89sUL/kVWRJ+PCJ66hDwCeAs4BlJCyUdX2E5rIk42Vgj+SvZH+uSESnWk43AFmB4LnZQBfvlh0xfQ9aUNDA37RER/yetnwmcm57jHAvcVeaYa4AzOx1n94hYm9YvBM4FdkuxhWRNfoOA5RWUE7LayuvAEblz7BcRe+e2uZYs0Q2VND4Xf9sw8RGxJCLGAe8CfgnMLlMOa2JONtZIZgL/KqlF0mCyZxD/0dNOEbEV+AXwbUl7SnofcMEOnvtm4CpJRwBI2k/SJ3PneJjsj/wtwPyIeLGb41yb61zQkp4HlSwEJgEPpOX70/If03V0ZT0wXNJuqSxvAj8Brpf0rnSeYZLOSPMnAxeRfQYTgB9JGtbVsSTtJumzkvaLiH8ALwPbPTcyAycbayzfBZYCjwCPAn9OsUpMIus88Bzw72SJ641KTxwRc4DvAbMkvQysAM7stNnPgNPSz3JuAOYCv5P0CrCYrCZUshDYh23J5o9kTWIPUN59wErgOUnPp9jXgXZgcSrv74HDJO0L3A5Mioi1EbGIrAPAT1MHh66OdT6wOh3ncuCz3ZTFmpSy5mQzy5P0PeDdEVFJrzQz64FrNmaApPdJer8yx5B1jZ5T63KZNQp/89kssw9Z09mBZM8lvg/cXdMSmTUQN6OZmVnh3IxmZmaFa7pmtMGDB0dra2uti2Fm1q8sW7bs+Yho6XnLrjVdsmltbWXp0qW1LoaZWb8i6ZmetyrPzWhmZlY4JxszMyuck42ZmRXOycbMzApXWLJJb/bbIGlFLvZzScvTtFrS8hRvlfR6bt3NuX2OlvSopHZJN+ZeQLW/pAWSnkg/B729FGZmVg+KrNncBozNByLi0xExOiJGkw2x/ovc6idL6yLi8lx8KtnLpkalqXTMycC9ETEKuDctm5lZHSos2UTEA2QvkHqbVDv5FNtem9slSUPJ3v63OL2A6nayV+YCjCN7OyHp59ldHMLMzOpArZ7ZnASsj4gncrGRkh5Ob/o7KcWGAR25bTpSDLI3F65L888BQ8qdTNJESUslLd24cWMfXYKZmVWqVslmPNvXatYBIyLiKOBK4GfpvRoVSbWesoO8RcS0iGiLiLaWll5/AdbMzHqp6iMISNoVOAc4uhSLiDdIL6qKiGWSngQOBday/at6h6cYwHpJQyNiXWpu21CN8tdC6+R73ppfPeUjNSyJmVnv1GK4mtOAv0TEW81jklqAzRGxVdLBZB0BnoqIzZJelnQc8CDZa2p/lHabS/bK2inpZ0MNB59PMGZm/V2RXZ9nAn8ie9Vsh6RL0qrzeHvHgJOBR1JX6DuByyOi1Lng82TvbW8HngR+k+JTgA9LeoIsgU0p6lrqTevke5yMzKxfKaxmExHjy8Qv7CJ2F1lX6K62Xwoc2UV8E3DqzpXSzMyqwSMImJlZ4ZxszMyscE42ZmZWOCcbMzMrnJONmZkVzsnGzMwK52RjZmaFc7IxM7PCOdmYmVnhnGzMzKxwTjZmZla4Woz6bH3Irx8ws/7ANRszMyucazZ1pFRL6W0NxbUcM6tXrtmYmVnhnGzMzKxwTjZmZlY4JxszMyuck42ZmRXOycbMzArnZGNmZoUrLNlImi5pg6QVudi3Ja2VtDxNZ+XWXSWpXdLjks7IxcemWLukybn4SEkPpvjPJe1W1LWYmdnOKbJmcxswtov49RExOk3zACQdDpwHHJH2+V+SBkgaANwEnAkcDoxP2wJ8Lx3rvcALwCUFXouZme2EwpJNRDwAbK5w83HArIh4IyKeBtqBY9LUHhFPRcTfgVnAOEkCTgHuTPvPAM7u0wtoAK2T79luVAEzs1qpxTObSZIeSc1sg1JsGLAmt01HipWLHwC8GBFbOsW7JGmipKWSlm7cuLGvrsPMzCpU7WQzFTgEGA2sA75fjZNGxLSIaIuItpaWlmqc0szMcqo6EGdErC/NS/oJ8Ou0uBY4KLfp8BSjTHwTMFDSrql2k9/ezMzqTFVrNpKG5hY/DpR6qs0FzpP0TkkjgVHAQ8ASYFTqebYbWSeCuRERwB+Ac9P+E4C7q3ENZma24wqr2UiaCYwBBkvqAK4GxkgaDQSwGrgMICJWSpoNrAK2AFdExNZ0nEnAfGAAMD0iVqZTfB2YJem7wMPArUVdi5mZ7ZzCkk1EjO8iXDYhRMS1wLVdxOcB87qIP0XWW83MzOqcRxAwM7PCOdmYmVnh/FroJuFXRptZLTnZ1JATgJk1CzejmZlZ4ZxszMyscE42ZmZWOCcbMzMrnJONmZkVzsnGzMwK567PTchdrs2s2lyzMTOzwjnZmJlZ4ZxszMyscE42ZmZWOCcbMzMrnJON0Tr5nu16qJmZ9TUnGzMzK5yTjZmZFc7JxszMCldYspE0XdIGSStysX+T9BdJj0iaI2lgirdKel3S8jTdnNvnaEmPSmqXdKMkpfj+khZIeiL9HFTUtZiZ2c4psmZzGzC2U2wBcGREvB/4f8BVuXVPRsToNF2ei08FLgVGpal0zMnAvRExCrg3LdtOKnUWcIcBM+tLhSWbiHgA2Nwp9ruI2JIWFwPDuzuGpKHAvhGxOCICuB04O60eB8xI8zNycTMzqzO1fGZzMfCb3PJISQ9LWijppBQbBnTktulIMYAhEbEuzT8HDCm0tGZm1ms1GfVZ0jeBLcAdKbQOGBERmyQdDfxS0hGVHi8iQlJ0c76JwESAESNG9L7gZmbWK1Wv2Ui6EPgo8NnUNEZEvBERm9L8MuBJ4FBgLds3tQ1PMYD1qZmt1Ny2odw5I2JaRLRFRFtLS0sfX5GZmfWkqslG0ljga8DHIuK1XLxF0oA0fzBZR4CnUjPZy5KOS73QLgDuTrvNBSak+Qm5uJmZ1ZnCmtEkzQTGAIMldQBXk/U+eyewIPVgXpx6np0MXCPpH8CbwOURUepc8Hmynm17kD3jKT3nmQLMlnQJ8AzwqaKupVn5JWtm1lcKSzYRMb6L8K1ltr0LuKvMuqXAkV3ENwGn7kwZzcysOjyCgJmZFc7JxszMCudkY2ZmhXOyMTOzwjnZmJlZ4ZxszMyscDUZrqaZ9efRlP29GzPrLddszMyscE42ZmZWOCcbMzMrnJONmZkVzsnGzMwK52RjZmaFc7IxM7PCOdmYmVnhnGzMzKxwHkHAesWjCZjZjnDNxvpE6+R7+vVQPGZWLCcbMzMrnJONmZkVzsnGzMwKV2iykTRd0gZJK3Kx/SUtkPRE+jkoxSXpRkntkh6R9MHcPhPS9k9ImpCLHy3p0bTPjZJU5PWYmVnvFF2zuQ0Y2yk2Gbg3IkYB96ZlgDOBUWmaCEyFLDkBVwPHAscAV5cSVNrm0tx+nc9lZmZ1oNBkExEPAJs7hccBM9L8DODsXPz2yCwGBkoaCpwBLIiIzRHxArAAGJvW7RsRiyMigNtzxzIzszpS0fdsJN0bEaf2FKvQkIhYl+afA4ak+WHAmtx2HSnWXbyji3hX5Z9IVltixIgRvSiy9Za/j2Nm0EOykbQ7sCcwODVdlZ6J7EuZP+w7IiJCUuzscSo4zzRgGkBbW1vh52t2/r6NmXXWU83mMuBLwIHAMrYlm5eBH/fynOslDY2IdakpbEOKrwUOym03PMXWAmM6xe9P8eFdbG9mZnWm22c2EXFDRIwEvhoRB0fEyDR9ICJ6m2zmAqUeZROAu3PxC1KvtOOAl1Jz23zgdEmDUu3qdGB+WveypONSL7QLcscyM7M6UtEzm4j4kaT/CrTm94mI27vbT9JMslrJYEkdZL3KpgCzJV0CPAN8Km0+DzgLaAdeAy5K59gs6TvAkrTdNRFR6nTwebIeb3sAv0mTmZnVmUo7CPw7cAiwHNiawqUeYGVFxPgyq97WsSD1KLuizHGmA9O7iC8FjuyuDFZfSs9z3FnArLlUOupzG3B4SghmZmY7pNJkswJ4N7Cupw3NKuVu0WbNo9JkMxhYJekh4I1SMCI+VkipzMysoVSabL5dZCHMzKyxVdobbWHRBTEzs8ZVaW+0V8h6nwHsBrwDeDUi9i2qYGZm1jgqrdnsU5pPX6AcBxxXVKHMzKyx7PCoz2lU5l+SjcZsZmbWo0qb0c7JLe5C9r2bvxVSImtK7gZt1tgq7Y3233PzW4DVZE1pZmZmPar0mc1FRRfEzMwaV0XPbCQNlzRH0oY03SVpeM97mpmZVd5B4KdkrwA4ME2/SjEzM7MeVZpsWiLipxGxJU23AS0FlquhtE6+x2+vNLOmVmmy2STpc5IGpOlzwKYiC2ZmZo2j0mRzMdlLzp4jG/n5XODCgspk5tqgWYOptOvzNcCEiHgBQNL+wHVkScjMzKxbldZs3l9KNJC9qhk4qpgimZlZo6m0ZrOLpEGdajaV7mu2U8o1p3mkAbP+o9KE8X3gT5L+d1r+JHBtMUUyM7NGU+kIArdLWgqckkLnRMSq4oplZmaNpOKmsJRcdjrBSDoM+HkudDDwLWAgcCmwMcW/ERHz0j5XAZcAW4EvRMT8FB8L3AAMAG6JiCk7Wz4zM+t7VX/uEhGPA6MBJA0A1gJzgIuA6yPiuvz2kg4HzgOOIBu94PeSDk2rbwI+DHQASyTNdY3LzKz+1Poh/6nAkxHxTPZOti6NA2ZFxBvA05LagWPSuvaIeApA0qy0rZONmVmd2eGXp/Wx84CZueVJkh6RNF3SoBQbBqzJbdORYuXibyNpoqSlkpZu3Lixq03MzKxANUs2knYDPgaUerhNBQ4ha2JbR9YDrk9ExLSIaIuItpYWD+lmZlZttWxGOxP4c0SsByj9BJD0E+DXaXEtcFBuv+EpRjdxaxKl7+D4Ozdm9a2WyWY8uSY0SUMjYl1a/DiwIs3PBX4m6QdkHQRGAQ8BAkZJGkmWZM4DPlOlslsd8qulzepXTZKNpL3IepFdlgv/T0mjgSB77fRlABGxUtJssgf/W4ArImJrOs4kYD5Z1+fpEbGyahdhZmYVq0myiYhXgQM6xc7vZvtr6WLEgvQ9nHl9XkAzM+tTte6NZmZmTaDW37MxK4Sf35jVF9dszMyscE42ZmZWOCcbawp+zbRZbfmZjTUdP88xqz7XbMzMrHBONmZmVjgnGzMzK5yTjZmZFc7JxszMCufeaNbU3DPNrDpcszEzs8I52Zjl+MufZsVwsjEzs8L5mY1ZGX6eY9Z3XLMxM7PCOdmYmVnhnGzMzKxwfmZTALf1N57O/6alZf/7mlXGNRszMytczZKNpNWSHpW0XNLSFNtf0gJJT6Sfg1Jckm6U1C7pEUkfzB1nQtr+CUkTanU9ZmZWXq2b0T4UEc/nlicD90bEFEmT0/LXgTOBUWk6FpgKHCtpf+BqoA0IYJmkuRHxQjUvwpqbm03NelZvzWjjgBlpfgZwdi5+e2QWAwMlDQXOABZExOaUYBYAY6tdaDMz614tk00Av5O0TNLEFBsSEevS/HPAkDQ/DFiT27cjxcrFtyNpoqSlkpZu3LixL6/BzMwqUMtmtBMjYq2kdwELJP0lvzIiQlL0xYkiYhowDaCtra1PjmnWFTepmXWtZskmItamnxskzQGOAdZLGhoR61Iz2Ya0+VrgoNzuw1NsLTCmU/z+gotuVjEnH7NMTZrRJO0laZ/SPHA6sAKYC5R6lE0A7k7zc4ELUq+044CXUnPbfOB0SYNSz7XTU8zMzOpIrWo2Q4A5kkpl+FlE/FbSEmC2pEuAZ4BPpe3nAWcB7cBrwEUAEbFZ0neAJWm7ayJic/Uuw8zMKlGTZBMRTwEf6CK+CTi1i3gAV5Q51nRgel+X0ayvuUnNmlm9dX02axp+UZs1EycbMzMrXK1HEDAz3MRmjc/JxqzOOPFYI3IzmpmZFc7JxszMCudkY1bn3GvNGoGTjZmZFc7JxszMCufeaGb9iHuqWX/lZGPWTznxWH/iZGPWIErJZ/WUjzgRWd3xMxszMyucazZmDc61HKsHrtmYmVnhnGzMzKxwTjZmTcYjElgt+JmNmQF+tmPFcrIxa2Ku4Vi1uBnNzLrk5jbrS67Z9BH/UpqZlVf1mo2kgyT9QdIqSSslfTHFvy1praTlaTort89VktolPS7pjFx8bIq1S5pc7WsxaxalWo7/U2W9VYuazRbgKxHxZ0n7AMskLUjrro+I6/IbSzocOA84AjgQ+L2kQ9Pqm4APAx3AEklzI2JVVa7CrEl17kiQHybHrJyqJ5uIWAesS/OvSHoMGNbNLuOAWRHxBvC0pHbgmLSuPSKeApA0K23rZGNmVmdq+sxGUitwFPAgcAIwSdIFwFKy2s8LZIlocW63DrYlpzWd4seWOc9EYCLAiBEj+u4CzGw77j5t5dSsN5qkvYG7gC9FxMvAVOAQYDRZzef7fXWuiJgWEW0R0dbS0tJXhzWzbnR+zuNnPs2tJjUbSe8gSzR3RMQvACJifW79T4Bfp8W1wEG53YenGN3EzcysjlQ92UgScCvwWET8IBcfmp7nAHwcWJHm5wI/k/QDsg4Co4CHAAGjJI0kSzLnAZ+pzlWY2c4oV8Nx01vjqkXN5gTgfOBRSctT7BvAeEmjgQBWA5cBRMRKSbPJHvxvAa6IiK0AkiYB84EBwPSIWFnNCzGzvufnPo2pFr3R/khWK+lsXjf7XAtc20V8Xnf7mVlj8dtI+y+PIGBmdcsJpXF4bDQzMyucazZm1u/1tgbk0Q+qx8nGzBqOn+3UHycbM2sa3SUed8culpONmdkOcE2pd5xsdoLbe82aQ7nfdSeeyjnZmJkVwIloe042ZmZ9pDetHc2SlJxszMwK5hfOOdmYmdWN7pJSf/8ukZONmVk/VC4R5e1Ih4aik5KHqzEzs8K5ZmNm1oR68wXXneGajZmZFc7JxszMCudkY2ZmhfMzmx3QLF++MjPra67ZmJlZ4ZxszMyscE42ZmZWuH7/zEbSWOAGYABwS0RM2dFjVLu/uZlZs+nXyUbSAOAm4MNAB7BE0tyIWNXTvt0lkXoZS8jMrFH092a0Y4D2iHgqIv4OzALG1bhMZmbWiSKi1mXoNUnnAmMj4p/T8vnAsRExqdN2E4GJafFIYEVVC1q/BgPP17oQdcKfxTb+LLbxZ7HNYRGxT2937tfNaJWKiGnANABJSyOircZFqgv+LLbxZ7GNP4tt/FlsI2npzuzf35vR1gIH5ZaHp5iZmdWR/p5slgCjJI2UtBtwHjC3xmUyM7NO+nUzWkRskTQJmE/W9Xl6RKzsYbdpxZes3/BnsY0/i238WWzjz2Kbnfos+nUHATMz6x/6ezOamZn1A042ZmZWuKZJNpLGSnpcUrukybUuTzVJOkjSHyStkrRS0hdTfH9JCyQ9kX4OqnVZq0XSAEkPS/p1Wh4p6cF0f/w8dThpeJIGSrpT0l8kPSbp+Ga9LyR9Of1+rJA0U9LuzXJfSJouaYOkFblYl/eBMjemz+QRSR+s5BxNkWxyw9qcCRwOjJd0eG1LVVVbgK9ExOHAccAV6fonA/dGxCjg3rTcLL4IPJZb/h5wfUS8F3gBuKQmpaq+G4DfRsT7gA+QfSZNd19IGgZ8AWiLiCPJOhydR/PcF7cBYzvFyt0HZwKj0jQRmFrJCZoi2dDkw9pExLqI+HOaf4XsD8owss9gRtpsBnB2bUpYXZKGAx8BbknLAk4B7kybNMVnIWk/4GTgVoCI+HtEvEiT3hdkvXP3kLQrsCewjia5LyLiAWBzp3C5+2AccHtkFgMDJQ3t6RzNkmyGAWtyyx0p1nQktQJHAQ8CQyJiXVr1HDCkRsWqth8CXwPeTMsHAC9GxJa03Cz3x0hgI/DT1KR4i6S9aML7IiLWAtcBz5IlmZeAZTTnfVFS7j7o1d/TZkk2BkjaG7gL+FJEvJxfF1kf+IbvBy/po8CGiFhW67LUgV2BDwJTI+Io4FU6NZk10X0xiOx/7COBA4G9eHuzUtPqi/ugWZJN0w9rI+kdZInmjoj4RQqvL1V/088NtSpfFZ0AfEzSarLm1FPInlsMTM0n0Dz3RwfQEREPpuU7yZJPM94XpwFPR8TGiPgH8Auye6UZ74uScvdBr/6eNkuyaephbdIziVuBxyLiB7lVc4EJaX4CcHe1y1ZtEXFVRAyPiFay++C+iPgs8Afg3LRZs3wWzwFrJB2WQqcCq2jC+4Ks+ew4SXum35fSZ9F090VOuftgLnBB6pV2HPBSrrmtrKYZQUDSWWRt9aVhba6tcZGqRtKJwCLgUbY9p/gG2XOb2cAI4BngUxHR+SFhw5I0BvhqRHxU0sFkNZ39gYeBz0XEG7UsXzVIGk3WUWI34CngIrL/hDbdfSHpfwCfJuu9+TDwz2TPIhr+vpA0ExhD9kqF9cDVwC/p4j5IyfjHZM2MrwEXRUSPI0I3TbIxM7PaaZZmNDMzqyEnGzMzK5yTjZmZFc7JxszMCudkY2ZmhXOyMdsJku6X1FaF83whjcp8R9HnSue7TdK5PW9pVpl+/Vpos/5M0q65cbd68nngtIjoqHE5zHrFNRtreJJaU63gJ+l9Jb+TtEda91bNRNLgNIwNki6U9Mv0Ho/VkiZJujINWLlY0v65U5wvaXl6D8oxaf+90jtCHkr7jMsdd66k+8iGbe9c1ivTcVZI+lKK3QwcDPxG0pc7bX+PpPen+YclfSvNXyPp0vQt739Lx3tU0qfT+jGSFkmaC6xK2/1Y2Tuffg+8K3eOKcrehfSIpOv64J/EmpBrNtYsRgHjI+JSSbOBTwD/0cM+R5KNkL070A58PSKOknQ9cAHZiBQAe0bEaEknA9PTft8kGwrnYkkDgYfSH3HIxh97f+dv5Us6muwb/McCAh6UtDAiLpc0FvhQRDzfqYyLgJMkPUP2zfcTUvwk4HLgHGA02btqBgNLJD2QK8eREfG0pHOAw8je9zSEbKiW6ZIOAD4OvC8iIl2L2Q5zzcaaxdMRsTzNLwNaK9jnDxHxSkRsJBty/lcp/min/WfCW+8E2Tf9QT4dmCxpOXA/WcIakbZfUGb4lxOBORHxakT8J9lgkCf1UMZFZO+kOQG4B9hb0p7AyIh4PB1zZkRsjYj1wELgv6R9H4qIp9P8ybnt/grcl+IvAX8Dbk0J6bUeymPWJddsrFnkx7PaCuyR5rew7T9du3ezz5u55TfZ/nen85hPQVYz+UT6g/8WSceSDeXfV5YAbWTjmi0gq71cSpZQe9JjOSJiS2oaPJVsQMpJZCNlm+0Q12ys2a0Gjk7zve19VXoOciLZCLgvAfOBf0mDFiLpqAqOswg4O408vBdZ89Wi7nZIb55dA3wS+FPa/qtAqalsEfBpSQMktZDVYB7q4lAP5LYbCnwolXtvYL+ImAd8maw5zmyHuWZjze46YLakiWTNUL3xN0kPA+8ALk6x75A903lE0i7A08BHuztIRPxZ0m1sSwa3RMTDFZx/EXBqRLwuaRHZ+0VKSWoOcDzwf8lqXF+LiOckva/TMeaQ1VhWkQ23/6cU3we4W9LuZLW1Kysoj9nbeNRnMzMrnJvRzMyscE42ZmZWOCcbMzMrnJONmZkVzsnGzMwK52RjZmaFc7IxM7PC/X/IWz8kBPR+kwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.bar(np.arange(len(text_length)),text_length)\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('number of words')\n",
        "plt.xlim([0,100])\n",
        "plt.title('long review texts')\n",
        "print('For long review texts, 90% of the data has <=', np.sum(text_length_cdf<0.9), 'words,', '95% of the data has <=', np.sum(text_length_cdf<0.95), 'words,', ' and 99% of the data has <=', np.sum(text_length_cdf<0.99), 'words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "_add2WAJMLzR",
        "outputId": "1995a5ee-7ff1-4d8e-bf3d-a90420a98335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For summaries, 90% of the data has <= 5 words, 95% of the data has <= 6 words,  and 99% of the data has <= 8 words\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.bar(np.arange(len(summary_length)),summary_length)\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('number of words')\n",
        "plt.xlim([0,20])\n",
        "plt.title('long review texts')\n",
        "print('For summaries, 90% of the data has <=', np.sum(summary_length_cdf<0.9), 'words,', '95% of the data has <=', np.sum(summary_length_cdf<0.95), 'words,', ' and 99% of the data has <=', np.sum(summary_length_cdf<0.99), 'words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHuHna-TMLzS"
      },
      "outputs": [],
      "source": [
        "start_token, end_token = '<SOS>' , '<EOS>'\n",
        "summary['Summary'] = summary['Summary'].apply(lambda x: start_token + ' ' + x + ' ' + end_token)\n",
        "review_text['Text'] = review_text['Text'].apply(lambda x: start_token + ' ' + x + ' ' + end_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKz2oeAPMLzS"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(list(summary['Summary'].values)+list(review_text['Text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ0UguePMLzT"
      },
      "outputs": [],
      "source": [
        "def read_embedding(filename):\n",
        "    \n",
        "    embeddings_index = {}\n",
        "    f = open(filename)\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    \n",
        "    return embeddings_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mcoBlezMLzT"
      },
      "outputs": [],
      "source": [
        "embeddings_index1 = read_embedding('glove.6B/glove.6B.50d.txt')\n",
        "embeddings_index2 = read_embedding('numberbatch-en-19.08.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg9D90WQMLzT"
      },
      "outputs": [],
      "source": [
        "# Check how good the words in pre-trained embeddings cover the reviews\n",
        "# calculate total number of words and unique words in the review\n",
        "n_words = np.sum(list(tokenizer.word_counts.values()))\n",
        "i_words = len(tokenizer.word_counts)\n",
        "\n",
        "# calculate the number of words appearing larger than 3, 5, and 10 times in the review\n",
        "i_words_3 = sum(count>3 for (word,count) in tokenizer.word_counts.items())\n",
        "i_words_5 = sum(count>5 for (word,count) in tokenizer.word_counts.items())\n",
        "i_words_10 = sum(count>10 for (word,count) in tokenizer.word_counts.items())\n",
        "\n",
        "# calculate the percentage of the reviews consisting of words appear larger than 3, 5, and 10 times\n",
        "n_words_3 = sum(count*(count>3) for (word,count) in tokenizer.word_counts.items())\n",
        "n_words_5 = sum(count*(count>5) for (word,count) in tokenizer.word_counts.items())\n",
        "n_words_10 = sum(count*(count>10) for (word,count) in tokenizer.word_counts.items())\n",
        "\n",
        "# calculate the number of words appearing > 3,5,10 times in the reivew are covered by the pretrained embeddings\n",
        "i_words_3_1 = sum((count>3 and word in embeddings_index1) for (word,count) in tokenizer.word_counts.items())\n",
        "i_words_3_2 = sum((count>3 and word in embeddings_index2) for (word,count) in tokenizer.word_counts.items())\n",
        "i_words_5_1 = sum((count>5 and word in embeddings_index1) for (word,count) in tokenizer.word_counts.items())\n",
        "i_words_5_2 = sum((count>5 and word in embeddings_index2) for (word,count) in tokenizer.word_counts.items())\n",
        "i_words_10_1 = sum((count>10 and word in embeddings_index1) for (word,count) in tokenizer.word_counts.items())\n",
        "i_words_10_2 = sum((count>10 and word in embeddings_index2) for (word,count) in tokenizer.word_counts.items())\n",
        "\n",
        "# caculate the percentage of the words in reviews appearing > 3,5,10 times are covered by the pretrained embeddings\n",
        "n_words_3_1 = sum(count*(count>3 and word in embeddings_index1) for (word,count) in tokenizer.word_counts.items())\n",
        "n_words_3_2 = sum(count*(count>3 and word in embeddings_index2) for (word,count) in tokenizer.word_counts.items())\n",
        "n_words_5_1 = sum(count*(count>5 and word in embeddings_index1) for (word,count) in tokenizer.word_counts.items())\n",
        "n_words_5_2 = sum(count*(count>5 and word in embeddings_index2) for (word,count) in tokenizer.word_counts.items())\n",
        "n_words_10_1 = sum(count*(count>10 and word in embeddings_index1) for (word,count) in tokenizer.word_counts.items())\n",
        "n_words_10_2 = sum(count*(count>10 and word in embeddings_index2) for (word,count) in tokenizer.word_counts.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok4A3q-pMLzU",
        "outputId": "97cff878-684b-4b2d-b48d-3f7d34cfa14c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 116453 unique words in the reviews, the total word number is 27806392 \n",
            "\n",
            "42.0 % of the unique words appear > 3 times. 99.7 % of the review words are these words. For words appearing > 3 times, 76.0 % are covered by the pretrained embedding glove-50, 98.8 % of the review words are these words. 73.0 % are covered by the pretrained embedding numberbatch, 97.8 % of the review words are these words.\n",
            "\n",
            "34.0 % of the unique words appear > 5 times. 99.5 % of the review words are these words. For words appearing > 5 times, 81.0 % are covered by the pretrained embedding glove-50, 98.8 % of the review words are these words. 78.0 % are covered by the pretrained embedding numberbatch, 97.8 % of the review words are these words.\n",
            "\n",
            "25.0 % of the unique words appear > 10 times. 99.2 % of the review words are these words. For words appearing > 10 times, 87.0 % are covered by the pretrained embedding glove-50, 98.6 % of the review words are these words. 84.0 % are covered by the pretrained embedding numberbatch, 97.6 % of the review words are these words.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"There are\", i_words, \"unique words in the reviews, the total word number is\", n_words,'\\n')\n",
        "\n",
        "print(round(i_words_3/i_words,2)*100, '% of the unique words appear > 3 times.', round(n_words_3/n_words,3)*100, '% of the review words are these words. For words appearing > 3 times,', round(i_words_3_1/i_words_3,2)*100, '% are covered by the pretrained embedding glove-50,', round(n_words_3_1/n_words,3)*100, '% of the review words are these words.', round(i_words_3_2/i_words_3,2)*100, '% are covered by the pretrained embedding numberbatch,', round(n_words_3_2/n_words,3)*100, '% of the review words are these words.\\n')\n",
        "\n",
        "print(round(i_words_5/i_words,2)*100, '% of the unique words appear > 5 times.', round(n_words_5/n_words,3)*100, '% of the review words are these words. For words appearing > 5 times,', round(i_words_5_1/i_words_5,2)*100, '% are covered by the pretrained embedding glove-50,', round(n_words_5_1/n_words,3)*100, '% of the review words are these words.', round(i_words_5_2/i_words_5,2)*100, '% are covered by the pretrained embedding numberbatch,', round(n_words_5_2/n_words,3)*100, '% of the review words are these words.\\n')\n",
        "\n",
        "print(round(i_words_10/i_words,2)*100, '% of the unique words appear > 10 times.', round(n_words_10/n_words,3)*100, '% of the review words are these words. For words appearing > 10 times,', round(i_words_10_1/i_words_10,2)*100, '% are covered by the pretrained embedding glove-50,', round(n_words_10_1/n_words,3)*100, '% of the review words are these words.', round(i_words_10_2/i_words_10,2)*100, '% are covered by the pretrained embedding numberbatch,', round(n_words_10_2/n_words,3)*100, '% of the review words are these words.\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJU_837JMLzV",
        "outputId": "771059a1-3cbe-4822-cac6-7e6ed9584fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['vinturi', 'landjaeger', 'tasts', 'chewies', 'disolves', 'gentlease', 'gfcf', 'caloire', 'tast', 'baconnaise', 'luzianne', 'delicous', 'softgels', 'decaff', 'goood', 'delish', 'tullys', 'whirley', 'glutino', 'evoo']\n"
          ]
        }
      ],
      "source": [
        "n = 20\n",
        "missingwords = []\n",
        "for (word,count) in tokenizer.word_counts.items():\n",
        "    if(n>0 and word not in embeddings_index1 and count > 10):\n",
        "        missingwords.append(word)\n",
        "        n -= 1\n",
        "print(missingwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW3KC2wcMLzW"
      },
      "outputs": [],
      "source": [
        "x_tr, x_val, y_tr, y_val = train_test_split(np.array(review_text['Text']), np.array(summary['Summary']), test_size=0.1, random_state=0, shuffle=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wucTTOdfMLzW"
      },
      "outputs": [],
      "source": [
        "tokenizer_model = Tokenizer(num_words=i_words_10+1, oov_token='<UNK>')\n",
        "tokenizer_model.fit_on_texts(list(summary['Summary'].values)+list(review_text['Text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnQAJcsGMLzW",
        "outputId": "3001bf20-aabc-4f33-945f-334341561465"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 9245]]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "tokenizer_model.texts_to_sequences(['<EOS> chocolove'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOR66NYpMLzX",
        "outputId": "a65e5f88-0510-46d3-d387-6fac383c47dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "new_dict = {}\n",
        "new_dict2 = {}\n",
        "new_dict['<UNK>'] = 1\n",
        "new_dict2[1] = '<UNK>'\n",
        "label = 2\n",
        "for (key, value) in tokenizer_model.word_index.items():\n",
        "    if(key != '<UNK>' and tokenizer_model.word_counts[key]>10 and key in embeddings_index1):\n",
        "        new_dict[key] = label\n",
        "        label +=1\n",
        "        new_dict2[value] = key\n",
        "\n",
        "tokenizer_model.word_index = new_dict\n",
        "tokenizer_model.index_word = new_dict2\n",
        "\n",
        "tokenizer_model.texts_to_sequences(['<EOS> choclate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIMfUG25MLzX"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(new_dict) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAcvmV0DMLzY"
      },
      "outputs": [],
      "source": [
        "#convert text sequences into integer sequences\n",
        "x_tr_seq = tokenizer_model.texts_to_sequences(x_tr)\n",
        "y_tr_seq = tokenizer_model.texts_to_sequences(y_tr)\n",
        "x_val_seq = tokenizer_model.texts_to_sequences(x_val)\n",
        "y_val_seq = tokenizer_model.texts_to_sequences(y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9arIUozNMLzZ"
      },
      "outputs": [],
      "source": [
        "max_len_text = 100\n",
        "max_len_summary = 10\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr_padded = pad_sequences(x_tr_seq,  maxlen=max_len_text, padding='post', truncating='post')\n",
        "x_val_padded = pad_sequences(x_val_seq, maxlen=max_len_text, padding='post', truncating='post')\n",
        "y_tr_padded = pad_sequences(y_tr_seq,  maxlen=max_len_summary, padding='post', truncating='post')\n",
        "y_val_padded = pad_sequences(y_val_seq, maxlen=max_len_summary, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ4RPBk4MLzb"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((x_tr_padded, y_tr_padded)).batch(BATCH_SIZE)\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices((x_val_padded,y_val_padded)).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_embeddings(filename, embedding_dim=50, vocab_size=100000):\n",
        "    \n",
        "    if(filename=='glove.6B/glove.6B.50d.txt'):\n",
        "        embedding_dim = 50\n",
        "        vocab_size = VOCAB_SIZE\n",
        "        embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "        for word, i in tokenizer_model.word_index.items():\n",
        "            embedding_vector = embeddings_index1.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "        \n",
        "        embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                            trainable=False)\n",
        "    \n",
        "    return embedding_layer"
      ],
      "metadata": {
        "id": "_JCppC-PVHmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "metadata": {
        "id": "U_R-nbwgSifL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "_rl0nd4lSkCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "metadata": {
        "id": "ymvWLq_SSnZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "metadata": {
        "id": "Phtr58hrSnf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "metadata": {
        "id": "wItY-D5_Snn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "HOQtUqeqSnux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "metadata": {
        "id": "mLVjKegjSn5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2"
      ],
      "metadata": {
        "id": "-qsGNG64Sn_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "id": "df0GRMK7TOsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1, embedding_filename=None):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    if(embedding_filename):\n",
        "      self.embedding = load_pretrained_embeddings(filename=embedding_filename)\n",
        "    else:\n",
        "      self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                            self.d_model)\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "metadata": {
        "id": "-OILurTDTOyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1, embedding_filename=None):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    if(embedding_filename):\n",
        "      self.embedding = load_pretrained_embeddings(filename=embedding_filename)\n",
        "    else:\n",
        "      self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "metadata": {
        "id": "rp2Y1ZOKTO8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1, embedding_filename=None):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size, pe_input, rate,\n",
        "                           embedding_filename=embedding_filename)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, pe_target, rate,\n",
        "                           embedding_filename=embedding_filename)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    # Keras models prefer if you pass all your inputs in the first argument\n",
        "    inp, tar = inputs\n",
        "\n",
        "    enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights\n",
        "\n",
        "  def create_masks(self, inp, tar):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, look_ahead_mask, dec_padding_mask"
      ],
      "metadata": {
        "id": "7q80zbnITPC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBchRBqTMLzl"
      },
      "outputs": [],
      "source": [
        "transformer_model = Transformer(num_layers=5,\n",
        "                                d_model=50,\n",
        "                                num_heads=5,\n",
        "                                dff=512,\n",
        "                                input_vocab_size=VOCAB_SIZE,\n",
        "                                target_vocab_size=VOCAB_SIZE,\n",
        "                                pe_input=max_len_text,\n",
        "                                pe_target=max_len_text,\n",
        "                                rate=0.15,\n",
        "                                embedding_filename='glove.6B/glove.6B.50d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ7Z1b5dMLzl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wadRAJxrMLzl"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=4000, decay_rate=0.95)\n",
        "optimizer = Adam(lr_schedule , beta_1=0.9, beta_2=0.98, epsilon=1e-9) \n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "#train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTHK8VXoMLzl"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    \n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate():\n",
        "    #print('validation started ...')\n",
        "    val_loss.reset_states()\n",
        "    for (batch, (inp, tar)) in enumerate(dataset_val):    \n",
        "        tar_inp = tar[:, :-1] # <startseq> hi im moein\n",
        "        tar_real = tar[:, 1:] # hi im moein <endseq>\n",
        "        predictions, _ = transformer_model(inputs=[inp, tar_inp], training=False)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "        val_loss(loss)\n",
        "    #print('\\n* Validation loss: {} '.format(val_loss.result()) )\n",
        "    return val_loss.result()"
      ],
      "metadata": {
        "id": "fN0EhfEoJTPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umKVE2-1MLzm"
      },
      "outputs": [],
      "source": [
        "@tf.function # Compiles a function into a callable TensorFlow graph\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1] \n",
        "    tar_real = tar[:, 1:] \n",
        "\n",
        "    #enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer_model(inputs=[inp, tar_inp], training=True)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer_model.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer_model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aZr2BQVpMLzm",
        "outputId": "fbcdc69a-b2bc-4e94-e65f-62443c2d512b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 10.1537 Time 11.77 secs\n",
            "Epoch 1 Batch 2000 Loss 6.4916 Time 82.07 secs\n",
            "Epoch 1 Batch 4000 Loss 5.9695 Time 152.26 secs\n",
            "Epoch 1 Batch 6000 Loss 5.7547 Time 222.47 secs\n",
            "Epoch 1 Batch 7954 Train Loss 5.6224 Valication Loss 5.1204 Time 448.79 secs\n",
            "Epoch 2 Batch 0 Loss 5.2982 Time 0.17 secs\n",
            "Epoch 2 Batch 2000 Loss 5.1326 Time 70.39 secs\n",
            "Epoch 2 Batch 4000 Loss 5.0968 Time 140.57 secs\n",
            "Epoch 2 Batch 6000 Loss 5.0675 Time 210.82 secs\n",
            "Epoch 2 Batch 7954 Train Loss 5.0441 Valication Loss 4.9057 Time 431.01 secs\n",
            "Epoch 3 Batch 0 Loss 5.0980 Time 0.10 secs\n",
            "Epoch 3 Batch 2000 Loss 4.9407 Time 70.35 secs\n",
            "Epoch 3 Batch 4000 Loss 4.9211 Time 140.59 secs\n",
            "Epoch 3 Batch 6000 Loss 4.9042 Time 210.83 secs\n",
            "Epoch 3 Batch 7954 Train Loss 4.8899 Valication Loss 4.7807 Time 429.85 secs\n",
            "Epoch 4 Batch 0 Loss 4.9511 Time 0.10 secs\n",
            "Epoch 4 Batch 2000 Loss 4.8245 Time 70.33 secs\n",
            "Epoch 4 Batch 4000 Loss 4.8070 Time 140.56 secs\n",
            "Epoch 4 Batch 6000 Loss 4.7928 Time 210.80 secs\n",
            "Epoch 4 Batch 7954 Train Loss 4.7814 Valication Loss 4.6832 Time 428.11 secs\n",
            "Epoch 5 Batch 0 Loss 4.8580 Time 0.11 secs\n",
            "Epoch 5 Batch 2000 Loss 4.7317 Time 70.32 secs\n",
            "Epoch 5 Batch 4000 Loss 4.7174 Time 140.53 secs\n",
            "Epoch 5 Batch 6000 Loss 4.7057 Time 210.72 secs\n",
            "Epoch 5 Batch 7954 Train Loss 4.6970 Valication Loss 4.6098 Time 428.36 secs\n",
            "Epoch 6 Batch 0 Loss 4.7815 Time 0.11 secs\n",
            "Epoch 6 Batch 2000 Loss 4.6622 Time 70.35 secs\n",
            "Epoch 6 Batch 4000 Loss 4.6502 Time 140.55 secs\n",
            "Epoch 6 Batch 6000 Loss 4.6409 Time 210.73 secs\n",
            "Epoch 6 Batch 7954 Train Loss 4.6347 Valication Loss 4.5553 Time 429.69 secs\n",
            "Epoch 7 Batch 0 Loss 4.7050 Time 0.10 secs\n",
            "Epoch 7 Batch 2000 Loss 4.6133 Time 70.34 secs\n",
            "Epoch 7 Batch 4000 Loss 4.6029 Time 140.58 secs\n",
            "Epoch 7 Batch 6000 Loss 4.5950 Time 210.85 secs\n",
            "Epoch 7 Batch 7954 Train Loss 4.5902 Valication Loss 4.5224 Time 429.00 secs\n",
            "Epoch 8 Batch 0 Loss 4.6509 Time 0.10 secs\n",
            "Epoch 8 Batch 2000 Loss 4.5740 Time 70.35 secs\n",
            "Epoch 8 Batch 4000 Loss 4.5648 Time 140.58 secs\n",
            "Epoch 8 Batch 6000 Loss 4.5581 Time 210.81 secs\n",
            "Epoch 8 Batch 7954 Train Loss 4.5539 Valication Loss 4.4909 Time 428.40 secs\n",
            "Epoch 9 Batch 0 Loss 4.6537 Time 0.10 secs\n",
            "Epoch 9 Batch 2000 Loss 4.5421 Time 70.34 secs\n",
            "Epoch 9 Batch 4000 Loss 4.5338 Time 140.57 secs\n",
            "Epoch 9 Batch 6000 Loss 4.5278 Time 210.81 secs\n",
            "Epoch 9 Batch 7954 Train Loss 4.5241 Valication Loss 4.4681 Time 428.22 secs\n",
            "Epoch 10 Batch 0 Loss 4.5266 Time 0.10 secs\n",
            "Epoch 10 Batch 2000 Loss 4.5169 Time 70.36 secs\n",
            "Epoch 10 Batch 4000 Loss 4.5086 Time 140.60 secs\n",
            "Epoch 10 Batch 6000 Loss 4.5030 Time 210.90 secs\n",
            "Epoch 10 Batch 7954 Train Loss 4.5003 Valication Loss 4.4482 Time 428.39 secs\n",
            "Epoch 11 Batch 0 Loss 4.5599 Time 0.10 secs\n",
            "Epoch 11 Batch 2000 Loss 4.4963 Time 70.32 secs\n",
            "Epoch 11 Batch 4000 Loss 4.4884 Time 140.58 secs\n",
            "Epoch 11 Batch 6000 Loss 4.4830 Time 210.81 secs\n",
            "Epoch 11 Batch 7954 Train Loss 4.4807 Valication Loss 4.4301 Time 428.17 secs\n",
            "Epoch 12 Batch 0 Loss 4.5508 Time 0.10 secs\n",
            "Epoch 12 Batch 2000 Loss 4.4792 Time 70.35 secs\n",
            "Epoch 12 Batch 4000 Loss 4.4719 Time 140.61 secs\n",
            "Epoch 12 Batch 6000 Loss 4.4668 Time 210.87 secs\n",
            "Epoch 12 Batch 7954 Train Loss 4.4643 Valication Loss 4.4153 Time 428.13 secs\n",
            "Epoch 13 Batch 0 Loss 4.5088 Time 0.10 secs\n",
            "Epoch 13 Batch 2000 Loss 4.4625 Time 70.37 secs\n",
            "Epoch 13 Batch 4000 Loss 4.4558 Time 140.63 secs\n",
            "Epoch 13 Batch 6000 Loss 4.4514 Time 210.90 secs\n",
            "Epoch 13 Batch 7954 Train Loss 4.4497 Valication Loss 4.4032 Time 428.18 secs\n",
            "Epoch 14 Batch 0 Loss 4.5535 Time 0.10 secs\n",
            "Epoch 14 Batch 2000 Loss 4.4511 Time 70.35 secs\n",
            "Epoch 14 Batch 4000 Loss 4.4443 Time 140.57 secs\n",
            "Epoch 14 Batch 6000 Loss 4.4396 Time 210.83 secs\n",
            "Epoch 14 Batch 7954 Train Loss 4.4376 Valication Loss 4.3909 Time 428.26 secs\n",
            "Epoch 15 Batch 0 Loss 4.5034 Time 0.10 secs\n",
            "Epoch 15 Batch 2000 Loss 4.4398 Time 70.33 secs\n",
            "Epoch 15 Batch 4000 Loss 4.4327 Time 140.56 secs\n",
            "Epoch 15 Batch 6000 Loss 4.4286 Time 210.84 secs\n",
            "Epoch 15 Batch 7954 Train Loss 4.4270 Valication Loss 4.3830 Time 428.61 secs\n",
            "Epoch 16 Batch 0 Loss 4.5357 Time 0.10 secs\n",
            "Epoch 16 Batch 2000 Loss 4.4308 Time 70.32 secs\n",
            "Epoch 16 Batch 4000 Loss 4.4242 Time 140.55 secs\n",
            "Epoch 16 Batch 6000 Loss 4.4201 Time 210.81 secs\n",
            "Epoch 16 Batch 7954 Train Loss 4.4183 Valication Loss 4.3734 Time 428.30 secs\n",
            "Epoch 17 Batch 0 Loss 4.4911 Time 0.10 secs\n",
            "Epoch 17 Batch 2000 Loss 4.4223 Time 70.38 secs\n",
            "Epoch 17 Batch 4000 Loss 4.4158 Time 140.62 secs\n",
            "Epoch 17 Batch 6000 Loss 4.4120 Time 210.87 secs\n",
            "Epoch 17 Batch 7954 Train Loss 4.4106 Valication Loss 4.3676 Time 428.27 secs\n",
            "Epoch 18 Batch 0 Loss 4.5150 Time 0.10 secs\n",
            "Epoch 18 Batch 2000 Loss 4.4170 Time 70.33 secs\n",
            "Epoch 18 Batch 4000 Loss 4.4095 Time 140.55 secs\n",
            "Epoch 18 Batch 6000 Loss 4.4055 Time 210.78 secs\n",
            "Epoch 18 Batch 7954 Train Loss 4.4042 Valication Loss 4.3610 Time 433.81 secs\n",
            "Epoch 19 Batch 0 Loss 4.5236 Time 0.10 secs\n",
            "Epoch 19 Batch 2000 Loss 4.4098 Time 70.35 secs\n",
            "Epoch 19 Batch 4000 Loss 4.4033 Time 140.59 secs\n",
            "Epoch 19 Batch 6000 Loss 4.4002 Time 210.86 secs\n",
            "Epoch 19 Batch 7954 Train Loss 4.3985 Valication Loss 4.3536 Time 429.28 secs\n",
            "Epoch 20 Batch 0 Loss 4.4864 Time 0.10 secs\n",
            "Epoch 20 Batch 2000 Loss 4.4033 Time 70.39 secs\n",
            "Epoch 20 Batch 4000 Loss 4.3970 Time 140.66 secs\n",
            "Epoch 20 Batch 6000 Loss 4.3938 Time 210.98 secs\n",
            "Epoch 20 Batch 7954 Train Loss 4.3930 Valication Loss 4.3491 Time 429.23 secs\n",
            "Epoch 21 Batch 0 Loss 4.4348 Time 0.10 secs\n",
            "Epoch 21 Batch 2000 Loss 4.3999 Time 70.41 secs\n",
            "Epoch 21 Batch 4000 Loss 4.3932 Time 140.71 secs\n",
            "Epoch 21 Batch 6000 Loss 4.3899 Time 211.02 secs\n",
            "Epoch 21 Batch 7954 Train Loss 4.3886 Valication Loss 4.3439 Time 428.70 secs\n",
            "Epoch 22 Batch 0 Loss 4.4653 Time 0.10 secs\n",
            "Epoch 22 Batch 2000 Loss 4.3944 Time 70.42 secs\n",
            "Epoch 22 Batch 4000 Loss 4.3885 Time 140.72 secs\n",
            "Epoch 22 Batch 6000 Loss 4.3858 Time 211.04 secs\n",
            "Epoch 22 Batch 7954 Train Loss 4.3850 Valication Loss 4.3402 Time 429.18 secs\n",
            "Epoch 23 Batch 0 Loss 4.4717 Time 0.10 secs\n",
            "Epoch 23 Batch 2000 Loss 4.3921 Time 70.45 secs\n",
            "Epoch 23 Batch 4000 Loss 4.3856 Time 140.75 secs\n",
            "Epoch 23 Batch 6000 Loss 4.3825 Time 211.06 secs\n",
            "Epoch 23 Batch 7954 Train Loss 4.3817 Valication Loss 4.3358 Time 428.93 secs\n",
            "Epoch 24 Batch 0 Loss 4.4539 Time 0.10 secs\n",
            "Epoch 24 Batch 2000 Loss 4.3908 Time 70.38 secs\n",
            "Epoch 24 Batch 4000 Loss 4.3837 Time 140.68 secs\n",
            "Epoch 24 Batch 6000 Loss 4.3808 Time 210.96 secs\n",
            "Epoch 24 Batch 7954 Train Loss 4.3793 Valication Loss 4.3318 Time 428.62 secs\n",
            "Epoch 25 Batch 0 Loss 4.4454 Time 0.10 secs\n",
            "Epoch 25 Batch 2000 Loss 4.3875 Time 70.42 secs\n",
            "Epoch 25 Batch 4000 Loss 4.3807 Time 140.71 secs\n",
            "Epoch 25 Batch 6000 Loss 4.3782 Time 211.01 secs\n",
            "Epoch 25 Batch 7954 Train Loss 4.3771 Valication Loss 4.3298 Time 428.88 secs\n",
            "Epoch 26 Batch 0 Loss 4.4196 Time 0.10 secs\n",
            "Epoch 26 Batch 2000 Loss 4.3849 Time 70.42 secs\n",
            "Epoch 26 Batch 4000 Loss 4.3790 Time 140.72 secs\n",
            "Epoch 26 Batch 6000 Loss 4.3760 Time 211.01 secs\n",
            "Epoch 26 Batch 7954 Train Loss 4.3747 Valication Loss 4.3263 Time 428.90 secs\n",
            "Epoch 27 Batch 0 Loss 4.4294 Time 0.10 secs\n",
            "Epoch 27 Batch 2000 Loss 4.3829 Time 70.48 secs\n",
            "Epoch 27 Batch 4000 Loss 4.3767 Time 140.83 secs\n",
            "Epoch 27 Batch 6000 Loss 4.3739 Time 211.16 secs\n",
            "Epoch 27 Batch 7954 Train Loss 4.3730 Valication Loss 4.3230 Time 429.55 secs\n",
            "Epoch 28 Batch 0 Loss 4.4520 Time 0.10 secs\n",
            "Epoch 28 Batch 2000 Loss 4.3817 Time 70.38 secs\n",
            "Epoch 28 Batch 4000 Loss 4.3748 Time 140.67 secs\n",
            "Epoch 28 Batch 6000 Loss 4.3719 Time 210.93 secs\n",
            "Epoch 28 Batch 7954 Train Loss 4.3710 Valication Loss 4.3205 Time 428.91 secs\n",
            "Epoch 29 Batch 0 Loss 4.4766 Time 0.10 secs\n",
            "Epoch 29 Batch 2000 Loss 4.3794 Time 70.43 secs\n",
            "Epoch 29 Batch 4000 Loss 4.3737 Time 140.72 secs\n",
            "Epoch 29 Batch 6000 Loss 4.3712 Time 211.02 secs\n",
            "Epoch 29 Batch 7954 Train Loss 4.3698 Valication Loss 4.3194 Time 429.17 secs\n",
            "Epoch 30 Batch 0 Loss 4.4181 Time 0.10 secs\n",
            "Epoch 30 Batch 2000 Loss 4.3801 Time 70.44 secs\n",
            "Epoch 30 Batch 4000 Loss 4.3732 Time 140.73 secs\n",
            "Epoch 30 Batch 6000 Loss 4.3706 Time 211.04 secs\n",
            "Epoch 30 Batch 7954 Train Loss 4.3694 Valication Loss 4.3172 Time 428.63 secs\n",
            "Epoch 31 Batch 0 Loss 4.4245 Time 0.10 secs\n",
            "Epoch 31 Batch 2000 Loss 4.3779 Time 70.43 secs\n",
            "Epoch 31 Batch 4000 Loss 4.3722 Time 140.73 secs\n",
            "Epoch 31 Batch 6000 Loss 4.3694 Time 211.08 secs\n",
            "Epoch 31 Batch 7954 Train Loss 4.3682 Valication Loss 4.3157 Time 429.30 secs\n",
            "Epoch 32 Batch 0 Loss 4.4675 Time 0.10 secs\n",
            "Epoch 32 Batch 2000 Loss 4.3781 Time 70.42 secs\n",
            "Epoch 32 Batch 4000 Loss 4.3710 Time 140.74 secs\n",
            "Epoch 32 Batch 6000 Loss 4.3686 Time 211.02 secs\n",
            "Epoch 32 Batch 7954 Train Loss 4.3675 Valication Loss 4.3134 Time 429.16 secs\n",
            "Epoch 33 Batch 0 Loss 4.3915 Time 0.10 secs\n",
            "Epoch 33 Batch 2000 Loss 4.3769 Time 70.38 secs\n",
            "Epoch 33 Batch 4000 Loss 4.3709 Time 140.70 secs\n",
            "Epoch 33 Batch 6000 Loss 4.3683 Time 211.04 secs\n",
            "Epoch 33 Batch 7954 Train Loss 4.3672 Valication Loss 4.3123 Time 430.20 secs\n",
            "Epoch 34 Batch 0 Loss 4.4689 Time 0.10 secs\n",
            "Epoch 34 Batch 2000 Loss 4.3762 Time 70.39 secs\n",
            "Epoch 34 Batch 4000 Loss 4.3704 Time 140.68 secs\n",
            "Epoch 34 Batch 6000 Loss 4.3680 Time 210.99 secs\n",
            "Epoch 34 Batch 7954 Train Loss 4.3672 Valication Loss 4.3110 Time 429.93 secs\n",
            "Epoch 35 Batch 0 Loss 4.4289 Time 0.10 secs\n",
            "Epoch 35 Batch 2000 Loss 4.3774 Time 70.41 secs\n",
            "Epoch 35 Batch 4000 Loss 4.3703 Time 140.68 secs\n",
            "Epoch 35 Batch 6000 Loss 4.3673 Time 210.95 secs\n",
            "Epoch 35 Batch 7954 Train Loss 4.3665 Valication Loss 4.3093 Time 428.62 secs\n",
            "Epoch 36 Batch 0 Loss 4.4681 Time 0.11 secs\n",
            "Epoch 36 Batch 2000 Loss 4.3763 Time 70.43 secs\n",
            "Epoch 36 Batch 4000 Loss 4.3696 Time 140.69 secs\n",
            "Epoch 36 Batch 6000 Loss 4.3670 Time 210.98 secs\n",
            "Epoch 36 Batch 7954 Train Loss 4.3661 Valication Loss 4.3086 Time 429.12 secs\n",
            "Epoch 37 Batch 0 Loss 4.4233 Time 0.10 secs\n",
            "Epoch 37 Batch 2000 Loss 4.3755 Time 70.35 secs\n",
            "Epoch 37 Batch 4000 Loss 4.3696 Time 140.63 secs\n",
            "Epoch 37 Batch 6000 Loss 4.3672 Time 210.88 secs\n",
            "Epoch 37 Batch 7954 Train Loss 4.3662 Valication Loss 4.3073 Time 429.29 secs\n",
            "Epoch 38 Batch 0 Loss 4.4058 Time 0.10 secs\n",
            "Epoch 38 Batch 2000 Loss 4.3761 Time 70.39 secs\n",
            "Epoch 38 Batch 4000 Loss 4.3696 Time 140.67 secs\n",
            "Epoch 38 Batch 6000 Loss 4.3675 Time 210.96 secs\n",
            "Epoch 38 Batch 7954 Train Loss 4.3666 Valication Loss 4.3066 Time 428.73 secs\n",
            "Epoch 39 Batch 0 Loss 4.5072 Time 0.11 secs\n",
            "Epoch 39 Batch 2000 Loss 4.3758 Time 70.40 secs\n",
            "Epoch 39 Batch 4000 Loss 4.3695 Time 140.67 secs\n",
            "Epoch 39 Batch 6000 Loss 4.3670 Time 210.97 secs\n",
            "Epoch 39 Batch 7954 Train Loss 4.3660 Valication Loss 4.3056 Time 429.33 secs\n",
            "Epoch 40 Batch 0 Loss 4.4680 Time 0.10 secs\n",
            "Epoch 40 Batch 2000 Loss 4.3755 Time 70.43 secs\n",
            "Epoch 40 Batch 4000 Loss 4.3691 Time 140.72 secs\n",
            "Epoch 40 Batch 6000 Loss 4.3668 Time 211.03 secs\n",
            "Epoch 40 Batch 7954 Train Loss 4.3655 Valication Loss 4.3048 Time 429.54 secs\n",
            "Epoch 41 Batch 0 Loss 4.4825 Time 0.10 secs\n",
            "Epoch 41 Batch 2000 Loss 4.3762 Time 70.38 secs\n",
            "Epoch 41 Batch 4000 Loss 4.3697 Time 140.66 secs\n",
            "Epoch 41 Batch 6000 Loss 4.3673 Time 210.90 secs\n",
            "Epoch 41 Batch 7954 Train Loss 4.3664 Valication Loss 4.3047 Time 429.46 secs\n",
            "Epoch 42 Batch 0 Loss 4.4218 Time 0.10 secs\n",
            "Epoch 42 Batch 2000 Loss 4.3752 Time 70.40 secs\n",
            "Epoch 42 Batch 4000 Loss 4.3686 Time 140.68 secs\n",
            "Epoch 42 Batch 6000 Loss 4.3662 Time 210.97 secs\n",
            "Epoch 42 Batch 7954 Train Loss 4.3655 Valication Loss 4.3041 Time 429.22 secs\n",
            "Epoch 43 Batch 0 Loss 4.4672 Time 0.10 secs\n",
            "Epoch 43 Batch 2000 Loss 4.3759 Time 70.39 secs\n",
            "Epoch 43 Batch 4000 Loss 4.3696 Time 140.65 secs\n",
            "Epoch 43 Batch 6000 Loss 4.3670 Time 210.97 secs\n",
            "Epoch 43 Batch 7954 Train Loss 4.3659 Valication Loss 4.3035 Time 429.46 secs\n",
            "Epoch 44 Batch 0 Loss 4.4845 Time 0.11 secs\n",
            "Epoch 44 Batch 2000 Loss 4.3761 Time 70.46 secs\n",
            "Epoch 44 Batch 4000 Loss 4.3691 Time 140.74 secs\n",
            "Epoch 44 Batch 6000 Loss 4.3668 Time 211.03 secs\n",
            "Epoch 44 Batch 7954 Train Loss 4.3657 Valication Loss 4.3030 Time 429.09 secs\n",
            "Epoch 45 Batch 0 Loss 4.4494 Time 0.10 secs\n",
            "Epoch 45 Batch 2000 Loss 4.3766 Time 70.36 secs\n",
            "Epoch 45 Batch 4000 Loss 4.3697 Time 140.64 secs\n",
            "Epoch 45 Batch 6000 Loss 4.3671 Time 210.89 secs\n",
            "Epoch 45 Batch 7954 Train Loss 4.3662 Valication Loss 4.3025 Time 428.60 secs\n",
            "Epoch 46 Batch 0 Loss 4.4212 Time 0.10 secs\n",
            "Epoch 46 Batch 2000 Loss 4.3761 Time 70.41 secs\n",
            "Epoch 46 Batch 4000 Loss 4.3689 Time 140.71 secs\n",
            "Epoch 46 Batch 6000 Loss 4.3667 Time 211.01 secs\n",
            "Epoch 46 Batch 7954 Train Loss 4.3657 Valication Loss 4.3022 Time 429.08 secs\n",
            "Epoch 47 Batch 0 Loss 4.4977 Time 0.10 secs\n",
            "Epoch 47 Batch 2000 Loss 4.3744 Time 70.40 secs\n",
            "Epoch 47 Batch 4000 Loss 4.3685 Time 140.71 secs\n",
            "Epoch 47 Batch 6000 Loss 4.3660 Time 211.00 secs\n",
            "Epoch 47 Batch 7954 Train Loss 4.3651 Valication Loss 4.3020 Time 429.31 secs\n",
            "Epoch 48 Batch 0 Loss 4.5150 Time 0.10 secs\n",
            "Epoch 48 Batch 2000 Loss 4.3751 Time 70.41 secs\n",
            "Epoch 48 Batch 4000 Loss 4.3692 Time 140.71 secs\n",
            "Epoch 48 Batch 6000 Loss 4.3669 Time 211.01 secs\n",
            "Epoch 48 Batch 7954 Train Loss 4.3658 Valication Loss 4.3017 Time 429.78 secs\n",
            "Epoch 49 Batch 0 Loss 4.4454 Time 0.10 secs\n",
            "Epoch 49 Batch 2000 Loss 4.3756 Time 70.43 secs\n",
            "Epoch 49 Batch 4000 Loss 4.3689 Time 140.66 secs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-0ea5e126623d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m#validate_loss = validate().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "history = {'train_loss':[], 'val_loss':[]}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    #train_accuracy.reset_states()\n",
        "\n",
        "    for (batch, (inp, tar)) in enumerate(dataset_train):\n",
        "        train_step(inp, tar)\n",
        "        if batch % 2000 == 0:\n",
        "            #validate_loss = validate().numpy()\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Time {time.time() - start:.2f} secs')\n",
        "            #print(f'Epoch {epoch + 1} Batch {batch} Train Loss {train_loss.result():.4f} Valication Loss {validate_loss:.4f} Time {time.time() - start:.2f} secs')\n",
        "    trained_loss = train_loss.result().numpy()\n",
        "    validate_loss = validate().numpy()\n",
        "    history['train_loss'].append(trained_loss)\n",
        "    history['val_loss'].append(validate_loss)\n",
        "    print(f'Epoch {epoch + 1} Batch {batch} Train Loss {train_loss.result():.4f} Valication Loss {validate_loss:.4f} Time {time.time() - start:.2f} secs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUL3Gu5VMLzm"
      },
      "outputs": [],
      "source": [
        "def validate():\n",
        "    print('validation started ...')\n",
        "    val_loss.reset_states()\n",
        "    for (batch, (inp, tar)) in enumerate(dataset_val):    \n",
        "        tar_inp = tar[:, :-1] \n",
        "        tar_real = tar[:, 1:] \n",
        "        predictions, _ = transformer_model(inputs=[inp, tar_inp], training=False)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "        val_loss(loss)\n",
        "    print('\\n* Validation loss: {} '.format(val_loss.result()) )\n",
        "    \n",
        "    return val_loss.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io3Y6paqMLzn"
      },
      "outputs": [],
      "source": [
        "def evaluate(input_document):\n",
        "    input_document = tokenizer_model.texts_to_sequences([input_document])\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=max_len_text, \n",
        "                                                                           padding='post', truncating='post')\n",
        "    \n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "    start_token = 'sos'\n",
        "    decoder_input = [tokenizer_model.word_index[start_token]]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(max_len_summary):\n",
        "        \n",
        "        predictions, attention_weights = transformer_model(inputs=[encoder_input, output], training = False)\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "        # stop prediciting if it reached end_token\n",
        "        end_token = 'eos'\n",
        "        if predicted_id == tokenizer_model.word_index[end_token]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "def summarize(input_document):\n",
        "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
        "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  # remove start_token\n",
        "    return tokenizer_model.sequences_to_texts(summarized)[0]  # since there is just one translated document"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i1 = 65\n",
        "print(x_tr[i1])\n",
        "print(summarize(clean_data(x_tr[i1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkUcrGArAJKu",
        "outputId": "a5d4e538-acbd-4c43-c171-c3630a487b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SOS> wonderful combination flavors proves heaven truly exists fan salt vinegar chips love almonds i have 2 cases counting shhhhhhhh <EOS>\n",
            "best chips ever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model.summary()"
      ],
      "metadata": {
        "id": "-apPC_qEANlO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copy of text_summerizer_transformer_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}